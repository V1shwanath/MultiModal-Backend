{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.04s/it]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image \n",
    "import requests \n",
    "from transformers import AutoModelForCausalLM ,BitsAndBytesConfig\n",
    "from transformers import AutoProcessor \n",
    "\n",
    "model_id = \"microsoft/Phi-3-vision-128k-instruct\" \n",
    "quant_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True\n",
    "        \n",
    "    )\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"cuda\", \n",
    "                                            trust_remote_code=True, torch_dtype=\"auto\", \n",
    "                                            _attn_implementation='flash_attention_2' ,\n",
    "                                            quantization_config =quant_config) #use _attn_implementation='eager' to disable flash attention\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "581"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [ \n",
    "    {\"role\": \"user\", \"content\": \"<|image_1|>\\nWhat is shown in the image?\"}, \n",
    "] \n",
    "\n",
    "\n",
    "image = Image.open('../images/image.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = processor.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "inputs = processor(prompt, [image], return_tensors=\"pt\").to(\"cuda:0\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jvish\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows a person riding a bicycle on a road with a field of yellow flowers in the background. There is a red car parked on the side of the road and a person walking in the distance. The sky is clear and blue.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generation_args = { \n",
    "    \"max_new_tokens\": 500, \n",
    "    \"temperature\": 0.0, \n",
    "    \"do_sample\": False, \n",
    "} \n",
    "\n",
    "generate_ids = model.generate(**inputs, eos_token_id=processor.tokenizer.eos_token_id, **generation_args) \n",
    "\n",
    "generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "response = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0] \n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ask a follow up quesiton from same image\n",
    "messages = [ \n",
    "    {\"role\": \"user\", \"content\": \"<|image_1|>\\nWhat is shown in this image?\"}, \n",
    "    {\"role\": \"assistant\", \"content\": response}, \n",
    "    {\"role\": \"user\", \"content\": \"What is the meaning of the image?\"},\n",
    "]\n",
    "\n",
    "prompt = processor.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "inputs = processor(prompt,return_tensors=\"pt\").to(\"cuda:0\") \n",
    "\n",
    "generation_args = { \n",
    "    \"max_new_tokens\": 500, \n",
    "    \"temperature\": 0.0, \n",
    "    \"do_sample\": False, \n",
    "} \n",
    "\n",
    "def stream_response(model, inputs, generation_args, processor):\n",
    "    generate_ids = model.generate(**inputs, eos_token_id=processor.tokenizer.eos_token_id, **generation_args, return_dict_in_generate=True, output_scores=True)\n",
    "    sequences = generate_ids.sequences[:, inputs['input_ids'].shape[1]:]\n",
    "    for token_id in sequences[0]:\n",
    "        token = processor.batch_decode(token_id.unsqueeze(0), skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "        yield token\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image conveys a sense of freedom, adventure, and the joy of outdoor activities. The person riding the bicycle appears to be enjoying the ride, and the open field and clear sky suggest a pleasant day for such activities.\n"
     ]
    }
   ],
   "source": [
    "#ask a follow up quesiton from same image\n",
    "messages = [ \n",
    "    {\"role\": \"user\", \"content\": \"<|image_1|>\\nWhat is shown in this image?\"}, \n",
    "    {\"role\": \"assistant\", \"content\": response}, \n",
    "    {\"role\": \"user\", \"content\": \"What is the meaning of the image?\"},\n",
    "]\n",
    "\n",
    "image = Image.open('../images/image.png')\n",
    "\n",
    "prompt = processor.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "inputs = processor(prompt, [image], return_tensors=\"pt\").to(\"cuda:0\") \n",
    "\n",
    "generation_args = { \n",
    "    \"max_new_tokens\": 500, \n",
    "    \"temperature\": 0.0, \n",
    "    \"do_sample\": False, \n",
    "} \n",
    "\n",
    "generate_ids = model.generate(**inputs, eos_token_id=processor.tokenizer.eos_token_id, **generation_args) \n",
    "\n",
    "# remove input tokens \n",
    "generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "response = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0] \n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch    \n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "The flowers in the field are yellow.\n"
     ]
    }
   ],
   "source": [
    "messages = [ \n",
    "    {\"role\": \"user\", \"content\": \"<|image_1|>\\nWhat is shown in this image?\"}, \n",
    "    {\"role\": \"assistant\", \"content\": response},\n",
    "        {\"role\": \"user\", \"content\": \"What is shown in this image?\"}, \n",
    "    {\"role\": \"assistant\", \"content\": response}, \n",
    "    {\"role\": \"user\", \"content\": \"What is color of flowers?\"},\n",
    "] \n",
    "\n",
    "image = Image.open('../images/image.png')\n",
    "\n",
    "prompt = processor.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "inputs = processor(prompt, [image], return_tensors=\"pt\").to(\"cuda:0\")\n",
    "\n",
    "generation_args = { \n",
    "    \"max_new_tokens\": 500, \n",
    "    \"temperature\": 0.0, \n",
    "    \"do_sample\": False, \n",
    "} \n",
    "\n",
    "generate_ids = model.generate(**inputs, eos_token_id=processor.tokenizer.eos_token_id, **generation_args) \n",
    "\n",
    "print(\"generating\")\n",
    "# remove input tokens \n",
    "generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "response = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0] \n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jvish\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "The sky is blue.\n"
     ]
    }
   ],
   "source": [
    "messages = [ \n",
    "    {\"role\": \"user\", \"content\": \"<|image_1|>\\nWhat is shown in this image?\"}, \n",
    "    {\"role\": \"assistant\", \"content\": response},\n",
    "    {\"role\": \"user\", \"content\": \"What is shown in this image?\"}, \n",
    "    {\"role\": \"assistant\", \"content\": response}, \n",
    "    {\"role\": \"user\", \"content\": \"What is color of flowers?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The flowers in the field are yellow.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the color of the sky?\"}\n",
    "] \n",
    "\n",
    "image = Image.open('../images/image.png')\n",
    "\n",
    "prompt = processor.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "inputs = processor(prompt, [image], return_tensors=\"pt\").to(\"cuda:0\")\n",
    "\n",
    "generation_args = { \n",
    "    \"max_new_tokens\": 500, \n",
    "    \"temperature\": 0.0, \n",
    "    \"do_sample\": False, \n",
    "} \n",
    "\n",
    "generate_ids = model.generate(**inputs, eos_token_id=processor.tokenizer.eos_token_id, **generation_args) \n",
    "\n",
    "print(\"generating\")\n",
    "# remove input tokens \n",
    "generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "response = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0] \n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jvish\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\jvish\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jvish\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\jvish\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-vision-128k-instruct. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-vision-128k-instruct:\n",
      "- configuration_phi3_v.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-vision-128k-instruct:\n",
      "- image_embedding_phi3_v.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-vision-128k-instruct:\n",
      "- modeling_phi3_v.py\n",
      "- image_embedding_phi3_v.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "c:\\Users\\jvish\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from PIL import Image \n",
    "import requests \n",
    "from transformers import AutoModelForCausalLM \n",
    "from transformers import AutoProcessor \n",
    "\n",
    "model_id = \"microsoft/Phi-3-vision-128k-instruct\" \n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"cuda\", trust_remote_code=True, torch_dtype=\"auto\", _attn_implementation='flash_attention_2') # use _attn_implementation='eager' to disable flash attention\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True) \n",
    "\n",
    "messages = [ \n",
    "    {\"role\": \"user\", \"content\": \"<|image_1|>\\nWhat is shown in this image?\"}, \n",
    "    {\"role\": \"assistant\", \"content\": \"The chart displays the percentage of respondents who agree with various statements about their preparedness for meetings. It shows five categories: 'Having clear and pre-defined goals for meetings', 'Knowing where to find the information I need for a meeting', 'Understanding my exact role and responsibilities when I'm invited', 'Having tools to manage admin tasks like note-taking or summarization', and 'Having more focus time to sufficiently prepare for meetings'. Each category has an associated bar indicating the level of agreement, measured on a scale from 0% to 100%.\"}, \n",
    "    {\"role\": \"user\", \"content\": \"Provide insightful questions to spark discussion.\"} \n",
    "] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages\\flash_attn-2.5.9.post1-py3.12-win-amd64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no image found in messages\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "\n",
    "if messages == []:\n",
    "    print(\"no image found in messages\")\n",
    "else:\n",
    "    print(\"image found in messages\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (1.2.1)\n",
      "Requirement already satisfied: requests>=2.28 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (2.32.3)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (2.6.4)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (0.110.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (1.26.4)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (4.10.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (1.18.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (1.25.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (0.19.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (4.66.2)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (6.4.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (1.64.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (4.1.3)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (0.12.3)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (30.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (8.2.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (6.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (4.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (3.10.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (4.41.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (2.3.1+cu121)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (1.13.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (0.23.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from build>=1.0.3->chromadb) (23.2)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.37.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.30.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=7.1,>=6.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (6.11.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.25.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.25.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.46b0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.46b0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.46b0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (69.2.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.28->chromadb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.28->chromadb) (3.6)\n",
      "Requirement already satisfied: networkx in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer>=0.9.0->chromadb) (12.6.0)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.18.1)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.11.0)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.17.2)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (3.7.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (1.3.1)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\jvish\\appdata\\local\\programs\\python\\python312\\lib\\site-packages\\flash_attn-2.5.9.post1-py3.12-win-amd64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "source": [
    "! pip install chromadb sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jvish\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 1:\n",
      " - Hello, how can I help you today?\n",
      " - I have an issue with my order.\n",
      " - Can you provide more details about your issue?\n",
      " - My order arrived damaged.\n",
      " - I'm sorry to hear that. We'll send a replacement right away.\n",
      "Level 2:\n",
      " - Thank you for your help.\n",
      " - How long will it take to arrive?\n",
      " - It should arrive in 3-5 business days.\n",
      " - Can I track my order?\n",
      " - Yes, you will receive a tracking number shortly.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "import numpy as np\n",
    "\n",
    "# Initialize conversation history at different levels\n",
    "lvl1_history = []\n",
    "lvl2_history = []\n",
    "lvl3_history = []\n",
    "\n",
    "class ConversationManager:\n",
    "    def __init__(self, level_threshold=5):\n",
    "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        self.client = chromadb.Client()\n",
    "        self.collection = self.client.create_collection(name=\"conversational2_embeddings\")\n",
    "        self.messages = []\n",
    "        self.level_threshold = level_threshold\n",
    "        self.current_level = 1\n",
    "\n",
    "    def add_message(self, message):\n",
    "        embedding = self.model.encode(message).tolist()  # Convert numpy array to list for ChromaDB\n",
    "        self.collection.add(embeddings=[embedding], metadatas=[{\"message\": message}], ids=[str(len(self.messages))])\n",
    "        self.messages.append(message)\n",
    "        self.update_level()\n",
    "\n",
    "    def update_level(self):\n",
    "        if len(self.messages) > self.level_threshold:\n",
    "            self.current_level += 1\n",
    "            self.level_threshold *= 2  # Adjust the threshold multiplier as needed\n",
    "\n",
    "    def print_messages_by_level(self):\n",
    "        # Simulate distributing messages into levels based on current_level and thresholds\n",
    "        levels = {i: [] for i in range(1, self.current_level + 1)}\n",
    "        current_threshold = 5\n",
    "        current_level = 1\n",
    "        \n",
    "        for i, message in enumerate(self.messages):\n",
    "            levels[current_level].append(message)\n",
    "            if len(levels[current_level]) >= current_threshold:\n",
    "                current_level += 1\n",
    "                current_threshold *= 2  # Adjust the threshold multiplier as needed\n",
    "\n",
    "        for level, msgs in levels.items():\n",
    "            print(f\"Level {level}:\")\n",
    "            for msg in msgs:\n",
    "                print(f\" - {msg}\")\n",
    "\n",
    "# Initialize the conversation manager\n",
    "conversation_manager = ConversationManager(level_threshold=5)\n",
    "\n",
    "# Simulating adding messages to ChromaDB\n",
    "messages = [\n",
    "    \"Hello, how can I help you today?\",\n",
    "    \"I have an issue with my order.\",\n",
    "    \"Can you provide more details about your issue?\",\n",
    "    \"My order arrived damaged.\",\n",
    "    \"I'm sorry to hear that. We'll send a replacement right away.\",\n",
    "    \"Thank you for your help.\",\n",
    "    \"How long will it take to arrive?\",\n",
    "    \"It should arrive in 3-5 business days.\",\n",
    "    \"Can I track my order?\",\n",
    "    \"Yes, you will receive a tracking number shortly.\",\n",
    "]\n",
    "\n",
    "# Add messages to ChromaDB\n",
    "for msg in messages:\n",
    "    conversation_manager.add_message(msg)\n",
    "\n",
    "# Print messages grouped by levels\n",
    "conversation_manager.print_messages_by_level()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
